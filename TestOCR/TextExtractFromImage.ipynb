{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pytesseract\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounding boxes around letter\n",
    "E' possibile individuare il bounding box che circonda ogni lettera individuata da Tesseract durante il processo di OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('temp\\\\page_1.jpg')\n",
    "\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "d = pytesseract.image_to_boxes(img, output_type=pytesseract.Output.DICT, config=custom_config)\n",
    "n_boxes = len(d['char'])\n",
    "for i in range(n_boxes):\n",
    "    (text,x1,y2,x2,y1) = (d['char'][i],d['left'][i],d['top'][i],d['right'][i],d['bottom'][i])\n",
    "    cv2.rectangle(img, (x1,height-y1), (x2,height-y2) , (0,255,0), 2)\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounding boxes around words\n",
    "\n",
    "In alternativa è possibile individuare le singole parole che sono presenti nell'immagine. Utilizzando la funzione image_to_data è possibile ottenere il dictionary con presenti le parole individuate, i rispettivi bounding box , il testo e il confidence scores di ogni parola.<br>\n",
    "\n",
    "Among the data returned by pytesseract.image_to_data():\n",
    "\n",
    "- left is the distance from the upper-left corner of the bounding box, to the left border of the image.\n",
    "- top is the distance from the upper-left corner of the bounding box, to the top border of the image.\n",
    "- width and height are the width and height of the bounding box.\n",
    "- conf is the model's confidence for the prediction for the word within that bounding box. If conf is -1, that means that the corresponding bounding box contains a block of text, rather than just a single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height', 'conf', 'text'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('invoice-sample.jpg')\n",
    "\n",
    "d = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "print(d.keys())\n",
    "\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    if int(d['conf'][i]) > 60:\n",
    "        (text,x, y, w, h) = (d['text'][i], d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione dati\n",
    "\n",
    "Utilizzando la funzione sopra indicata (image_to_data) è possibile estrarre testo dal corpo dell'immagine.  Nell'esempio sotto riportato ad esempio si estrae la data presente nel documento sulla base di una regexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12/2001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "img = cv2.imread('invoice-sample.jpg')\n",
    "\n",
    "d = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "date_pattern = '^(0[1-9]|[12][0-9]|3[01])/(0[1-9]|1[012])/(19|20)\\d\\d$'\n",
    "\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    if int(d['conf'][i]) > 60:\n",
    "        if re.match(date_pattern, d['text'][i]):\n",
    "            print(d['text'][i])\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('temp\\\\page_1.jpg')\n",
    "\n",
    "gray = get_grayscale(img)\n",
    "thresh = thresholding(gray)\n",
    "opening = opening(gray)\n",
    "canny = canny(gray)\n",
    "\n",
    "cv2.imshow('gray', gray)\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.imshow('opening', opening)\n",
    "cv2.imshow('canny', canny)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:michele]",
   "language": "python",
   "name": "conda-env-michele-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
